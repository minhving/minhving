# Minh Vi Nguyen ‚Äî AI Engineer / Applied ML

I build **production-minded AI systems**: data ‚Üí models ‚Üí evaluation ‚Üí APIs ‚Üí deployment.  
Current focus: **Computer Vision pipelines**, **RAG/LLM systems**, and **MLOps** (Docker, CI/CD).

- üìç Melbourne, Australia
- üéì BCompSci (AI), La Trobe University (GPA 91/100) | Provost‚Äôs Commendation 2024
- üî≠ Interested in: CV, RAG, agents, evaluation, deployment, responsible AI

## Quick Links
- GitHub: https://github.com/minhving
- LinkedIn: https://www.linkedin.com/in/minhvinguyen
- Portfolio: https://www.minhvinguyen.com
- Email: minhvi176@gmail.com

---

## Tech Stack (Engineering-Focused)

### Languages
- **Python**, JavaScript/TypeScript, SQL

### ML / AI
- **PyTorch**, scikit-learn (and exposure to TensorFlow)
- **Computer Vision**: detection, segmentation, depth estimation
- **LLMs**: OpenAI / Claude / Gemini
- **RAG**: embeddings, chunking, retrieval, grounding & evaluation

### LLM / Agent Frameworks
- LangChain, LlamaIndex, LangGraph, CrewAI

### Data & Search
- Pandas, NumPy
- Vector DB: FAISS, Pinecone

### Backend & Infra
- **FastAPI**
- **Docker**
- CI/CD: GitHub Actions
- Cloud exposure: **AWS** (S3, Lambda, SageMaker, Bedrock), Azure, GCP

---

## What I‚Äôm Good At (Signals)
- Designing **end-to-end AI workflows** (not just notebooks)
- Building **modular pipelines** (clear interfaces between stages)
- Shipping models behind **APIs** with reproducibility (Docker)
- Doing **evaluation properly**: metrics, ablations, error analysis, iteration loops
- Communicating with stakeholders: turning vague needs into measurable outputs


---

## How I Like to Build (My Default Workflow)
1. **Define success** (metric + acceptable error)
2. **Baseline fast** (simple pipeline, measurable)
3. **Instrument** (logging, dataset versioning, eval scripts)
4. **Iterate** (ablation + error analysis)
5. **Deploy** (API + Docker)
6. **Monitor** (drift/quality checks where applicable)

---
